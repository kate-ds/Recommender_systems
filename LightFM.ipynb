{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ответьте на вопросы:**\n",
    "\n",
    "__1.__ \n",
    "- В чем принципиальное отличие гибридных рекомендательных систем от коллаборативной филтьтрации?\n",
    "\n",
    "*В коллаборативной фильтрации учитываются только взаимодействия user-item, и никак не учитываются их характеристики. Это делает сложным рекомендации для новых пользователей и товаров. В гибридных рекомендательных системах учитываются не только взаимодействия, но и признаки пользователей и товаров. Это позволяет улучшить качество рекомендации и делать рекомендации для \"холодных\" пользователей и товаров*\n",
    "\n",
    "\n",
    "- Приведите 2-3 примера задач, в которых необходимо использовать гибридные системы\n",
    "\n",
    "*Гибридные системы лучше использовать там, где постоянно обновляется контент и появляется много новых пользователей. Например, маркетплейсы - Amazon, Ozon, Joom, там постоянно обновляются товалы, добавляются новые и исчезают старые, приходят новые пользователи. Или YouTube (новые видеозаписи), hh.ru (новые вакансии), также каждый день приходит много новых пользователей.*\n",
    "\n",
    "WARP loss объяснение на игрушечном примере  - [статья](https://medium.com/@gabrieltseng/intro-to-warp-loss-automatic-differentiation-and-pytorch-b6aa5083187a)\n",
    "\n",
    "\n",
    "__2.__  Прочитайте статью про поиск на hh.ru https://habr.com/ru/company/hh/blog/347276/\n",
    "Нам интересна именно рекомендательная система, раздел \"Производительность системы\" можно пропустить\n",
    "Какие основные отличия предложенной системы от тех подходов, которые мы разбирали на семинарах? Какие проблемы могут возникнуть при выводе такой модели в продакшен? \n",
    "\n",
    "*Основное отличие в том, что в hh используется несколько уровней, в которых каждый фильтр на основании некоего количиства признаков отбирает вакансии тем самым, с каждым разом уменьшая подборку и финальная модель уже делает финальное ранжирование по всем признаком, выдавая в итоге топ самых релевантных. Проблема при выводе в продакшен - время ранжирования XGBoost - алгоритм работает очень медленно и на пересчет модели может быть недостаточно времени*\n",
    "\n",
    "__3.__ На вебинаре мы рассматривали модель LightFM (https://making.lyst.com/lightfm/docs/lightfm.html). В работе Data Scientist'а важную часть занимает research - исследование существующих архитектур и разбор научных статей, в которых они описываются. Вам предлагается изчуть оригинальную статью про LightFM https://arxiv.org/pdf/1507.08439.pdf и ответить на следующие вопросы:  \n",
    "1) Какой датасет используют авторы?  \n",
    "*Используют два датасета - MovieLens - с рейтингами фильмов и датасет CrossValidated с вопросами и ответами с сервиса*\n",
    "\n",
    "2) Что используют в качестве признаков?   \n",
    "*В первом датасете содержатся рейтинги фильмов проставленные 71,6 тыс пользователей на 10,7 тыс фильмов, все фильмы описаны жанром и тегами с Tag Genome. Каждая пара фильм-тэг содержит скор релевантности (от 0 до 1), который показывает, насколько близко тэг описывает фильм. Так же, автор перевел в бинарное представление рейтинги и отметил рейтинги ниже 4 как отрицательные, а выше - как положительные взаимоддействия. Дополнительно, автор отфильтровал тэги, которые не релевантны фильму (по значению отсечки, равную 0.8)\n",
    "Второй датасет содержит почти 6 тыс пользователей, 44,2 тыс вопросов, 188,9 тыс ответов и комментариев с сервиса на котором задают вопросы по машинному обучению. Также есть метаданные пользователей, тэги вопросов*\n",
    "\n",
    "3) С какими моделями сравнивают LightFM? Опишите их основные идеи кратко  \n",
    "\n",
    "* MF: матричная модель факторизации со смещениями пользователя и айтема и связывающей сигмоидой.  \n",
    "LSI-LR: модель, основанная на контенете. Айтемы представляют в виде комбинации латентных тем, которые извлегаются с помощью латентного сементического индексирования (LSI), затем используется обычкая модель логистической регрессии.  \n",
    "LSI-UP: гибридная модель, которая представляет пользовательские профили как комбинацию векторов айтемов, затем применяется LSI к результирующей матрице, чтобы получить латентное юзер-айтем представление, затем применяется SVD*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Модуль SRC  \n",
    "\n",
    "На вебинаре было рассказано про модуль src. Он приложен в материалах. Скачайте его, изучите структуру, импортируйте функции\n",
    "\n",
    "### 2. Работа с признаками  \n",
    "\n",
    "У нас есть внешние данные. Что с ними не так? Чего не хватает?  \n",
    "\n",
    "Проведите исследование внешних данных и составьте какие-нибудь содержательные выводы.  \n",
    "Формально Вам нужно построить 3+ графиков (scatter plot, hist или что-то иное) и описать, что мы видим (например, товары такой-то категории болле часто покупаются в следующие дни недели или пользователи с большим достатком предпочитают такие-то товары).  \n",
    "Исследуйте те закономерности, которые Вам интересно, чем менее тривиальный вывод получается, тем лучше! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: lightfm in /usr/local/lib/python3.8/site-packages (1.16)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/site-packages (from lightfm) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/site-packages (from lightfm) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from lightfm) (1.19.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from lightfm) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->lightfm) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->lightfm) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/site-packages (from requests->lightfm) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->lightfm) (2020.6.20)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/site-packages (from scikit-learn->lightfm) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn->lightfm) (2.1.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# from metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2277416</th>\n",
       "      <td>338</td>\n",
       "      <td>41260573635</td>\n",
       "      <td>636</td>\n",
       "      <td>840173</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277417</th>\n",
       "      <td>338</td>\n",
       "      <td>41260573635</td>\n",
       "      <td>636</td>\n",
       "      <td>1037348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>369</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277418</th>\n",
       "      <td>338</td>\n",
       "      <td>41260573635</td>\n",
       "      <td>636</td>\n",
       "      <td>5592737</td>\n",
       "      <td>2</td>\n",
       "      <td>1.58</td>\n",
       "      <td>369</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277419</th>\n",
       "      <td>338</td>\n",
       "      <td>41260573635</td>\n",
       "      <td>636</td>\n",
       "      <td>7441679</td>\n",
       "      <td>1</td>\n",
       "      <td>3.69</td>\n",
       "      <td>369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277420</th>\n",
       "      <td>338</td>\n",
       "      <td>41260573635</td>\n",
       "      <td>636</td>\n",
       "      <td>7442317</td>\n",
       "      <td>1</td>\n",
       "      <td>2.69</td>\n",
       "      <td>369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "2277416      338  41260573635  636   840173         1         1.99       369   \n",
       "2277417      338  41260573635  636  1037348         1         0.89       369   \n",
       "2277418      338  41260573635  636  5592737         2         1.58       369   \n",
       "2277419      338  41260573635  636  7441679         1         3.69       369   \n",
       "2277420      338  41260573635  636  7442317         1         2.69       369   \n",
       "\n",
       "         retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "2277416          0.0         112       92          0.0                0.0  \n",
       "2277417         -0.3         112       92          0.0                0.0  \n",
       "2277418         -0.2         112       92          0.0                0.0  \n",
       "2277419          0.0         112       92          0.0                0.0  \n",
       "2277420          0.0         112       92          0.0                0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('retail_train.csv')\n",
    "\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>25-34K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "2    25-34                   U      25-34K        Unknown     2 Adults Kids   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  \n",
       "2                   3                 1        8  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26093</td>\n",
       "      <td>69</td>\n",
       "      <td>PASTRY</td>\n",
       "      <td>Private</td>\n",
       "      <td>BREAD</td>\n",
       "      <td>BREAD:ITALIAN/FRENCH</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "2    26093            69        PASTRY   Private                     BREAD   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       \n",
       "2         BREAD:ITALIAN/FRENCH                       "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GROCERY            39021\n",
       "DRUG GM            31529\n",
       "PRODUCE             3118\n",
       "COSMETICS           3011\n",
       "NUTRITION           2914\n",
       "MEAT                2544\n",
       "MEAT-PCKGD          2427\n",
       "DELI                2354\n",
       "PASTRY              2149\n",
       "FLORAL               938\n",
       "SEAFOOD-PCKGD        563\n",
       "MISC. TRANS.         490\n",
       "SPIRITS              377\n",
       "SEAFOOD              369\n",
       "GARDEN CENTER        128\n",
       "RESTAURANT           102\n",
       "MISC SALES TRAN       88\n",
       "SALAD BAR             48\n",
       "COUP/STR & MFG        39\n",
       "TRAVEL & LEISUR       28\n",
       "FROZEN GROCERY        23\n",
       "KIOSK-GAS             16\n",
       "                      15\n",
       "CHEF SHOPPE           14\n",
       "RX                     9\n",
       "CNTRL/STORE SUP        4\n",
       "TOYS                   3\n",
       "VIDEO RENTAL           3\n",
       "POSTAL CENTER          3\n",
       "DAIRY DELI             3\n",
       "GM MERCH EXP           3\n",
       "PHOTO                  2\n",
       "PROD-WHS SALES         2\n",
       "VIDEO                  2\n",
       "CHARITABLE CONT        2\n",
       "AUTOMOTIVE             2\n",
       "GRO BAKERY             2\n",
       "DELI/SNACK BAR         2\n",
       "MEAT-WHSE              1\n",
       "PORK                   1\n",
       "ELECT &PLUMBING        1\n",
       "HOUSEWARES             1\n",
       "HBC                    1\n",
       "PHARMACY SUPPLY        1\n",
       "Name: department, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.department.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GROCERY', 'MISC. TRANS.', 'PASTRY', 'DRUG GM', 'MEAT-PCKGD',\n",
       "       'SEAFOOD-PCKGD', 'PRODUCE', 'NUTRITION', 'DELI', 'COSMETICS',\n",
       "       'MEAT', 'FLORAL', 'TRAVEL & LEISUR', 'SEAFOOD', 'MISC SALES TRAN',\n",
       "       'SALAD BAR', 'KIOSK-GAS', 'ELECT &PLUMBING', 'GRO BAKERY',\n",
       "       'GM MERCH EXP', 'FROZEN GROCERY', 'COUP/STR & MFG', 'SPIRITS',\n",
       "       'GARDEN CENTER', 'TOYS', 'CHARITABLE CONT', 'RESTAURANT', 'RX',\n",
       "       'PROD-WHS SALES', 'MEAT-WHSE', 'DAIRY DELI', 'CHEF SHOPPE', 'HBC',\n",
       "       'DELI/SNACK BAR', 'PORK', 'AUTOMOTIVE', 'VIDEO RENTAL', ' ',\n",
       "       'CNTRL/STORE SUP', 'HOUSEWARES', 'POSTAL CENTER', 'PHOTO', 'VIDEO',\n",
       "       'PHARMACY SUPPLY'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.department.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52189</th>\n",
       "      <td>5126087</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52190</th>\n",
       "      <td>5126088</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52191</th>\n",
       "      <td>5126106</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52192</th>\n",
       "      <td>5126107</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55048</th>\n",
       "      <td>5977100</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55054</th>\n",
       "      <td>5978648</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55055</th>\n",
       "      <td>5978649</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55056</th>\n",
       "      <td>5978650</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55057</th>\n",
       "      <td>5978656</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55058</th>\n",
       "      <td>5978657</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55059</th>\n",
       "      <td>5978659</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55277</th>\n",
       "      <td>5993051</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55278</th>\n",
       "      <td>5993054</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55279</th>\n",
       "      <td>5993055</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58244</th>\n",
       "      <td>6693056</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>National</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  manufacturer department     brand commodity_desc  \\\n",
       "52189  5126087             1             National                  \n",
       "52190  5126088             1             National                  \n",
       "52191  5126106             1             National                  \n",
       "52192  5126107             1             National                  \n",
       "55048  5977100             1             National                  \n",
       "55054  5978648             1             National                  \n",
       "55055  5978649             1             National                  \n",
       "55056  5978650             1             National                  \n",
       "55057  5978656             1             National                  \n",
       "55058  5978657             1             National                  \n",
       "55059  5978659             1             National                  \n",
       "55277  5993051             1             National                  \n",
       "55278  5993054             1             National                  \n",
       "55279  5993055             1             National                  \n",
       "58244  6693056             1             National                  \n",
       "\n",
       "      sub_commodity_desc curr_size_of_product  \n",
       "52189                                          \n",
       "52190                                          \n",
       "52191                                          \n",
       "52192                                          \n",
       "55048                                          \n",
       "55054                                          \n",
       "55055                                          \n",
       "55056                                          \n",
       "55057                                          \n",
       "55058                                          \n",
       "55059                                          \n",
       "55277                                          \n",
       "55278                                          \n",
       "55279                                          \n",
       "58244                                          "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.loc[item_features.department == ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных по продуктам есть категория без названия, в которой не заполнены и остальные поля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     39021\n",
       "1     31529\n",
       "2      3118\n",
       "3      3011\n",
       "4      2914\n",
       "5      2544\n",
       "6      2427\n",
       "7      2354\n",
       "8      2149\n",
       "9       938\n",
       "10      563\n",
       "11      490\n",
       "12      377\n",
       "13      369\n",
       "14      128\n",
       "15      102\n",
       "16       88\n",
       "17       48\n",
       "18       39\n",
       "19       28\n",
       "20       23\n",
       "21       16\n",
       "22       15\n",
       "23       14\n",
       "24        9\n",
       "Name: department, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_then_5_categories.department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "categories_count = item_features.department.value_counts().reset_index().rename(columns={'index': 'department',\n",
    "                                                                                        'department': 'quantity'})\n",
    "more_then_5_categories = categories_count.loc[categories_count.quantity > 5]\n",
    "sns.barplot(more_then_5_categories.quantity, more_then_5_categories.department,\n",
    "           orient='h')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>...</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>POTATOES</td>\n",
       "      <td>POTATOES RUSSET (BULK&amp;BAG)</td>\n",
       "      <td>5 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>ONIONS</td>\n",
       "      <td>ONIONS SWEET (BULK&amp;BAG)</td>\n",
       "      <td>40 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1036325</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>VEGETABLES - ALL OTHERS</td>\n",
       "      <td>CELERY</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1082185</td>\n",
       "      <td>1</td>\n",
       "      <td>1.21</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>TROPICAL FRUIT</td>\n",
       "      <td>BANANAS</td>\n",
       "      <td>40 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>8160430</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>ORGANICS FRUIT &amp; VEGETABLES</td>\n",
       "      <td>ORGANIC CARROTS</td>\n",
       "      <td>1 LB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>826249</td>\n",
       "      <td>2</td>\n",
       "      <td>1.98</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>BAKED BREAD/BUNS/ROLLS</td>\n",
       "      <td>HAMBURGER BUNS</td>\n",
       "      <td>12 OZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>1043142</td>\n",
       "      <td>1</td>\n",
       "      <td>1.57</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>BROOMS AND MOPS</td>\n",
       "      <td>SPONGES: BATH HOUSEHOLD</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>1085983</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>TRAY PACK/CHOC CHIP COOKIES</td>\n",
       "      <td>18 OZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>1102651</td>\n",
       "      <td>1</td>\n",
       "      <td>1.89</td>\n",
       "      <td>364</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>PNT BTR/JELLY/JAMS</td>\n",
       "      <td>PEANUT BUTTER</td>\n",
       "      <td>12 OZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>6423775</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>GRAHAM CRACKERS</td>\n",
       "      <td>11 OZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851516</td>\n",
       "      <td>1</td>\n",
       "      <td>9487839</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>1642</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>GRAHAM CRACKERS</td>\n",
       "      <td>11 OZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>842930</td>\n",
       "      <td>1</td>\n",
       "      <td>2.19</td>\n",
       "      <td>31742</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>CONVENIENT BRKFST/WHLSM SNACKS</td>\n",
       "      <td>GRANOLA BARS</td>\n",
       "      <td>10 OZ</td>\n",
       "      <td>65+</td>\n",
       "      <td>B</td>\n",
       "      <td>100-124K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>Single Female</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>897044</td>\n",
       "      <td>1</td>\n",
       "      <td>2.99</td>\n",
       "      <td>31742</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>CRACKERS/MISC BKD FD</td>\n",
       "      <td>SNACK CRACKERS</td>\n",
       "      <td>9.5 OZ</td>\n",
       "      <td>65+</td>\n",
       "      <td>B</td>\n",
       "      <td>100-124K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>Single Female</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>920955</td>\n",
       "      <td>1</td>\n",
       "      <td>3.09</td>\n",
       "      <td>31742</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>BEEF</td>\n",
       "      <td>GRND/PATTY - ROUND</td>\n",
       "      <td></td>\n",
       "      <td>65+</td>\n",
       "      <td>B</td>\n",
       "      <td>100-124K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>Single Female</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1364</td>\n",
       "      <td>26984896261</td>\n",
       "      <td>1</td>\n",
       "      <td>937406</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>31742</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>BREAKFAST SAUSAGE/SANDWICHES</td>\n",
       "      <td>LINKS - RAW</td>\n",
       "      <td>12OZ</td>\n",
       "      <td>65+</td>\n",
       "      <td>B</td>\n",
       "      <td>100-124K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>Single Female</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0      2375  26984851472    1  1004906         1         1.39       364   \n",
       "1      2375  26984851472    1  1033142         1         0.82       364   \n",
       "2      2375  26984851472    1  1036325         1         0.99       364   \n",
       "3      2375  26984851472    1  1082185         1         1.21       364   \n",
       "4      2375  26984851472    1  8160430         1         1.50       364   \n",
       "5      2375  26984851516    1   826249         2         1.98       364   \n",
       "6      2375  26984851516    1  1043142         1         1.57       364   \n",
       "7      2375  26984851516    1  1085983         1         2.99       364   \n",
       "8      2375  26984851516    1  1102651         1         1.89       364   \n",
       "9      2375  26984851516    1  6423775         1         2.00       364   \n",
       "10     2375  26984851516    1  9487839         1         2.00       364   \n",
       "11     1364  26984896261    1   842930         1         2.19     31742   \n",
       "12     1364  26984896261    1   897044         1         2.99     31742   \n",
       "13     1364  26984896261    1   920955         1         3.09     31742   \n",
       "14     1364  26984896261    1   937406         1         2.50     31742   \n",
       "\n",
       "    retail_disc  trans_time  week_no  ...                  commodity_desc  \\\n",
       "0         -0.60        1631        1  ...                        POTATOES   \n",
       "1          0.00        1631        1  ...                          ONIONS   \n",
       "2         -0.30        1631        1  ...         VEGETABLES - ALL OTHERS   \n",
       "3          0.00        1631        1  ...                  TROPICAL FRUIT   \n",
       "4         -0.39        1631        1  ...     ORGANICS FRUIT & VEGETABLES   \n",
       "5         -0.60        1642        1  ...          BAKED BREAD/BUNS/ROLLS   \n",
       "6         -0.68        1642        1  ...                 BROOMS AND MOPS   \n",
       "7         -0.40        1642        1  ...                   COOKIES/CONES   \n",
       "8          0.00        1642        1  ...              PNT BTR/JELLY/JAMS   \n",
       "9         -0.79        1642        1  ...                   COOKIES/CONES   \n",
       "10        -0.79        1642        1  ...                   COOKIES/CONES   \n",
       "11         0.00        1520        1  ...  CONVENIENT BRKFST/WHLSM SNACKS   \n",
       "12        -0.40        1520        1  ...            CRACKERS/MISC BKD FD   \n",
       "13         0.00        1520        1  ...                            BEEF   \n",
       "14        -0.99        1520        1  ...    BREAKFAST SAUSAGE/SANDWICHES   \n",
       "\n",
       "             sub_commodity_desc  curr_size_of_product age_desc  \\\n",
       "0    POTATOES RUSSET (BULK&BAG)                  5 LB      NaN   \n",
       "1       ONIONS SWEET (BULK&BAG)                 40 LB      NaN   \n",
       "2                        CELERY                            NaN   \n",
       "3                       BANANAS                 40 LB      NaN   \n",
       "4               ORGANIC CARROTS                  1 LB      NaN   \n",
       "5                HAMBURGER BUNS                 12 OZ      NaN   \n",
       "6       SPONGES: BATH HOUSEHOLD                            NaN   \n",
       "7   TRAY PACK/CHOC CHIP COOKIES                 18 OZ      NaN   \n",
       "8                 PEANUT BUTTER                 12 OZ      NaN   \n",
       "9               GRAHAM CRACKERS                 11 OZ      NaN   \n",
       "10              GRAHAM CRACKERS                 11 OZ      NaN   \n",
       "11                 GRANOLA BARS                 10 OZ      65+   \n",
       "12               SNACK CRACKERS                9.5 OZ      65+   \n",
       "13           GRND/PATTY - ROUND                            65+   \n",
       "14                  LINKS - RAW                  12OZ      65+   \n",
       "\n",
       "   marital_status_code income_desc homeowner_desc   hh_comp_desc  \\\n",
       "0                  NaN         NaN            NaN            NaN   \n",
       "1                  NaN         NaN            NaN            NaN   \n",
       "2                  NaN         NaN            NaN            NaN   \n",
       "3                  NaN         NaN            NaN            NaN   \n",
       "4                  NaN         NaN            NaN            NaN   \n",
       "5                  NaN         NaN            NaN            NaN   \n",
       "6                  NaN         NaN            NaN            NaN   \n",
       "7                  NaN         NaN            NaN            NaN   \n",
       "8                  NaN         NaN            NaN            NaN   \n",
       "9                  NaN         NaN            NaN            NaN   \n",
       "10                 NaN         NaN            NaN            NaN   \n",
       "11                   B    100-124K      Homeowner  Single Female   \n",
       "12                   B    100-124K      Homeowner  Single Female   \n",
       "13                   B    100-124K      Homeowner  Single Female   \n",
       "14                   B    100-124K      Homeowner  Single Female   \n",
       "\n",
       "   household_size_desc kid_category_desc  \n",
       "0                  NaN               NaN  \n",
       "1                  NaN               NaN  \n",
       "2                  NaN               NaN  \n",
       "3                  NaN               NaN  \n",
       "4                  NaN               NaN  \n",
       "5                  NaN               NaN  \n",
       "6                  NaN               NaN  \n",
       "7                  NaN               NaN  \n",
       "8                  NaN               NaN  \n",
       "9                  NaN               NaN  \n",
       "10                 NaN               NaN  \n",
       "11                   1      None/Unknown  \n",
       "12                   1      None/Unknown  \n",
       "13                   1      None/Unknown  \n",
       "14                   1      None/Unknown  \n",
       "\n",
       "[15 rows x 25 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data_train, item_features, on='item_id', how='left')\n",
    "data = pd.merge(data, user_features, on='user_id', how='left')\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'basket_id', 'day', 'item_id', 'quantity', 'sales_value',\n",
       "       'store_id', 'retail_disc', 'trans_time', 'week_no', 'coupon_disc',\n",
       "       'coupon_match_disc', 'manufacturer', 'department', 'brand',\n",
       "       'commodity_desc', 'sub_commodity_desc', 'curr_size_of_product',\n",
       "       'age_desc', 'marital_status_code', 'income_desc', 'homeowner_desc',\n",
       "       'hh_comp_desc', 'household_size_desc', 'kid_category_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(item_features.department.value_counts() < 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые обширные категории товаров - 'Grocery', 'Drug GM'. Есть категории, в которых менее 5 позиций, всего таких 19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082185     26127\n",
       "6534178     17545\n",
       "1029743     12737\n",
       "995242      10943\n",
       "1106523      8722\n",
       "            ...  \n",
       "505149          1\n",
       "13097497        1\n",
       "12757687        1\n",
       "76487           1\n",
       "12582342        1\n",
       "Name: item_id, Length: 86865, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26093</td>\n",
       "      <td>69</td>\n",
       "      <td>PASTRY</td>\n",
       "      <td>Private</td>\n",
       "      <td>BREAD</td>\n",
       "      <td>BREAD:ITALIAN/FRENCH</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26190</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>FRUIT - SHELF STABLE</td>\n",
       "      <td>APPLE SAUCE</td>\n",
       "      <td>50 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26355</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>COOKIES/CONES</td>\n",
       "      <td>SPECIALTY COOKIES</td>\n",
       "      <td>14 OZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "2    26093            69        PASTRY   Private                     BREAD   \n",
       "3    26190            69       GROCERY   Private      FRUIT - SHELF STABLE   \n",
       "4    26355            69       GROCERY   Private             COOKIES/CONES   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       \n",
       "2         BREAD:ITALIAN/FRENCH                       \n",
       "3                  APPLE SAUCE                50 OZ  \n",
       "4            SPECIALTY COOKIES                14 OZ  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>25-34K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>75-99K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45-54</td>\n",
       "      <td>B</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>Single Female</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "2    25-34                   U      25-34K        Unknown     2 Adults Kids   \n",
       "3    25-34                   U      75-99K      Homeowner     2 Adults Kids   \n",
       "4    45-54                   B      50-74K      Homeowner     Single Female   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  \n",
       "2                   3                 1        8  \n",
       "3                   4                 2       13  \n",
       "4                   1      None/Unknown       16  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['65+', '45-54', '25-34', '35-44', '19-24', '55-64'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features['age_desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'U', 'B'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features['marital_status_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "data.groupby(['age_desc', 'marital_status_code'])['user_id'].count().plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Больше всего покупок делают люди в возрасте 35-44 с семейным статусом \"А\" и 44-54 со статусами \"А\" и \"U\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "data.groupby(['department'])['sales_value'].sum().sort_values().plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что по сумме покупок по-прежнему самые денежные - Grocery и Drug DM. Посмотрим, как в этих категориях меняется сумма покупок в каждую неделю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.week_no.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PRODUCE', 'GROCERY', 'DRUG GM', 'MEAT', 'MEAT-PCKGD', 'DELI',\n",
       "       'SEAFOOD-PCKGD', ' ', 'PASTRY', 'NUTRITION', 'VIDEO RENTAL',\n",
       "       'MISC SALES TRAN', 'FLORAL', 'SEAFOOD', 'SALAD BAR', 'AUTOMOTIVE',\n",
       "       'SPIRITS', 'COSMETICS', 'MISC. TRANS.', 'GARDEN CENTER',\n",
       "       'CHEF SHOPPE', 'TRAVEL & LEISUR', 'COUP/STR & MFG', 'KIOSK-GAS',\n",
       "       'FROZEN GROCERY', 'RESTAURANT', 'HOUSEWARES', 'PORK',\n",
       "       'POSTAL CENTER', 'GM MERCH EXP', 'CNTRL/STORE SUP',\n",
       "       'PROD-WHS SALES', 'DAIRY DELI', 'HBC', 'CHARITABLE CONT', 'RX',\n",
       "       'TOYS', 'PHOTO', 'DELI/SNACK BAR', 'GRO BAKERY', 'PHARMACY SUPPLY',\n",
       "       'ELECT &PLUMBING', 'MEAT-WHSE', 'VIDEO'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.department.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "data.loc[data.department == 'GROCERY'].groupby('week_no')['sales_value'].sum().sort_index().plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "data.loc[data.department == 'DRUG GM'].groupby('week_no')['sales_value'].sum().sort_index().plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в примерно 15 первых недель сумма покупок ниже, чем дальше, скорее всего это связано с тем, что в первое время сеть набирала обороты по продажам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "На графике "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Filter items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items_train from 86865 to 5001\n",
      "Decreased # items_test from 24329 to 5001\n",
      "Decreased # users_train from 2499 to 2497\n",
      "Decreased # users_test from 2042 to 1990\n"
     ]
    }
   ],
   "source": [
    "n_items_train_before = data_train['item_id'].nunique()\n",
    "n_items_test_before = data_test['item_id'].nunique()\n",
    "n_users_train_before = data_train['user_id'].nunique()\n",
    "n_users_test_before = data_test['user_id'].nunique()\n",
    "\n",
    "data_train_filtered = prefilter_items(data_train, take_n_popular=5000, item_features=item_features)\n",
    "data_test_filtered = prefilter_items(data_test, take_n_popular=5000, item_features=item_features)\n",
    "\n",
    "n_items_train_after = data_train_filtered['item_id'].nunique()\n",
    "n_items_test_after = data_test_filtered['item_id'].nunique()\n",
    "n_users_train_after = data_train_filtered['user_id'].nunique()\n",
    "n_users_test_after = data_test_filtered['user_id'].nunique()\n",
    "print('Decreased # items_train from {} to {}'.format(n_items_train_before, n_items_train_after))\n",
    "print('Decreased # items_test from {} to {}'.format(n_items_test_before, n_items_test_after))\n",
    "print('Decreased # users_train from {} to {}'.format(n_users_train_before, n_users_train_after))\n",
    "print('Decreased # users_test from {} to {}'.format(n_users_test_before, n_users_test_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Prepare data set\n",
    "\n",
    "## 2.1 Prepare csr train matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>117847</th>\n",
       "      <th>818981</th>\n",
       "      <th>819255</th>\n",
       "      <th>819308</th>\n",
       "      <th>819400</th>\n",
       "      <th>819487</th>\n",
       "      <th>819590</th>\n",
       "      <th>819594</th>\n",
       "      <th>819840</th>\n",
       "      <th>819845</th>\n",
       "      <th>...</th>\n",
       "      <th>15926775</th>\n",
       "      <th>15926844</th>\n",
       "      <th>15926886</th>\n",
       "      <th>15972074</th>\n",
       "      <th>15972298</th>\n",
       "      <th>15972565</th>\n",
       "      <th>15972790</th>\n",
       "      <th>16100266</th>\n",
       "      <th>16729299</th>\n",
       "      <th>16729415</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  117847    818981    819255    819308    819400    819487    819590    \\\n",
       "user_id                                                                         \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "item_id  819594    819840    819845    ...  15926775  15926844  15926886  \\\n",
       "user_id                                ...                                 \n",
       "1             0.0       0.0       0.0  ...       0.0       1.0       0.0   \n",
       "2             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "item_id  15972074  15972298  15972565  15972790  16100266  16729299  16729415  \n",
       "user_id                                                                        \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[2 rows x 5001 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix = pd.pivot_table(data_train_filtered,\n",
    "                                  index='user_id', columns='item_id',\n",
    "                                  values='quantity', # Можно пробовать другие варианты\n",
    "                                  aggfunc='count',\n",
    "                                  fill_value=0\n",
    "                                  )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Prepare CSR test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>819210</th>\n",
       "      <th>819308</th>\n",
       "      <th>819423</th>\n",
       "      <th>819487</th>\n",
       "      <th>819840</th>\n",
       "      <th>819845</th>\n",
       "      <th>819978</th>\n",
       "      <th>820321</th>\n",
       "      <th>820347</th>\n",
       "      <th>820352</th>\n",
       "      <th>...</th>\n",
       "      <th>17381676</th>\n",
       "      <th>17381995</th>\n",
       "      <th>17827241</th>\n",
       "      <th>17900997</th>\n",
       "      <th>17901020</th>\n",
       "      <th>17903379</th>\n",
       "      <th>17903423</th>\n",
       "      <th>17959083</th>\n",
       "      <th>18000012</th>\n",
       "      <th>18024556</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  819210    819308    819423    819487    819840    819845    819978    \\\n",
       "user_id                                                                         \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "item_id  820321    820347    820352    ...  17381676  17381995  17827241  \\\n",
       "user_id                                ...                                 \n",
       "1             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "3             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "item_id  17900997  17901020  17903379  17903423  17959083  18000012  18024556  \n",
       "user_id                                                                        \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[2 rows x 5001 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warm start - берем только те user_id, которые есть в train\n",
    "data_test = data_test[data_test['user_id'].isin(data_train['user_id'])]\n",
    "\n",
    "test_user_item_matrix = pd.pivot_table(data_test_filtered,\n",
    "                                       index='user_id', columns='item_id',\n",
    "                                       values='quantity', # Можно пробовать другие варианты\n",
    "                                       aggfunc='count',\n",
    "                                       fill_value=0\n",
    "                                       )\n",
    "\n",
    "test_user_item_matrix = test_user_item_matrix.astype(float)\n",
    "\n",
    "test_sparse_user_item_matrix = csr_matrix(test_user_item_matrix).tocsr() # необходимый тип матрицы для implicit\n",
    "\n",
    "test_user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Prepare user and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25-34</td>\n",
       "      <td>U</td>\n",
       "      <td>25-34K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2 Adults Kids</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_desc marital_status_code income_desc homeowner_desc  \\\n",
       "user_id                                                           \n",
       "1            65+                   A      35-49K      Homeowner   \n",
       "2            NaN                 NaN         NaN            NaN   \n",
       "3            NaN                 NaN         NaN            NaN   \n",
       "4            NaN                 NaN         NaN            NaN   \n",
       "5            NaN                 NaN         NaN            NaN   \n",
       "6            NaN                 NaN         NaN            NaN   \n",
       "7          45-54                   A      50-74K      Homeowner   \n",
       "8          25-34                   U      25-34K        Unknown   \n",
       "9            NaN                 NaN         NaN            NaN   \n",
       "10           NaN                 NaN         NaN            NaN   \n",
       "\n",
       "             hh_comp_desc household_size_desc kid_category_desc  \n",
       "user_id                                                          \n",
       "1        2 Adults No Kids                   2      None/Unknown  \n",
       "2                     NaN                 NaN               NaN  \n",
       "3                     NaN                 NaN               NaN  \n",
       "4                     NaN                 NaN               NaN  \n",
       "5                     NaN                 NaN               NaN  \n",
       "6                     NaN                 NaN               NaN  \n",
       "7        2 Adults No Kids                   2      None/Unknown  \n",
       "8           2 Adults Kids                   3                 1  \n",
       "9                     NaN                 NaN               NaN  \n",
       "10                    NaN                 NaN               NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "user_feat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test_user_feat = pd.DataFrame(test_user_item_matrix.index)\n",
    "# test_user_feat = test_user_feat.merge(user_features, on='user_id', how='left')\n",
    "# test_user_feat.set_index('user_id', inplace=True)\n",
    "# test_user_feat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2497, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat.shape\\\n",
    "    # , test_user_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117847</th>\n",
       "      <td>450.0</td>\n",
       "      <td>NUTRITION</td>\n",
       "      <td>National</td>\n",
       "      <td>REFRIGERATED</td>\n",
       "      <td>SOY/RICE MILK</td>\n",
       "      <td>64 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818981</th>\n",
       "      <td>194.0</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>COLD CEREAL</td>\n",
       "      <td>ALL FAMILY CEREAL</td>\n",
       "      <td>10.4 OZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819255</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>MEAT-PCKGD</td>\n",
       "      <td>National</td>\n",
       "      <td>BREAKFAST SAUSAGE/SANDWICHES</td>\n",
       "      <td>ROLLS - PORK</td>\n",
       "      <td>1 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819308</th>\n",
       "      <td>2879.0</td>\n",
       "      <td>MEAT</td>\n",
       "      <td>National</td>\n",
       "      <td>BEEF</td>\n",
       "      <td>CHOICE BEEF</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819400</th>\n",
       "      <td>584.0</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>DOG FOODS</td>\n",
       "      <td>DOG TREATS (SOFT TREATS)</td>\n",
       "      <td>5.6 OZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         manufacturer  department     brand                commodity_desc  \\\n",
       "item_id                                                                     \n",
       "117847          450.0   NUTRITION  National                  REFRIGERATED   \n",
       "818981          194.0     GROCERY  National                   COLD CEREAL   \n",
       "819255         1007.0  MEAT-PCKGD  National  BREAKFAST SAUSAGE/SANDWICHES   \n",
       "819308         2879.0        MEAT  National                          BEEF   \n",
       "819400          584.0     GROCERY  National                     DOG FOODS   \n",
       "\n",
       "               sub_commodity_desc curr_size_of_product  \n",
       "item_id                                                 \n",
       "117847              SOY/RICE MILK                64 OZ  \n",
       "818981          ALL FAMILY CEREAL              10.4 OZ  \n",
       "819255               ROLLS - PORK                 1 LB  \n",
       "819308                CHOICE BEEF                       \n",
       "819400   DOG TREATS (SOFT TREATS)               5.6 OZ  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "item_feat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test_item_feat = pd.DataFrame(test_user_item_matrix.columns)\n",
    "# test_item_feat = test_item_feat.merge(item_features, on='item_id', how='left')\n",
    "# test_item_feat.set_index('item_id', inplace=True)\n",
    "#\n",
    "# test_item_feat.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feat.shape\\\n",
    "    # , test_item_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manufacturer_2.0</th>\n",
       "      <th>manufacturer_5.0</th>\n",
       "      <th>manufacturer_16.0</th>\n",
       "      <th>manufacturer_20.0</th>\n",
       "      <th>manufacturer_26.0</th>\n",
       "      <th>manufacturer_33.0</th>\n",
       "      <th>manufacturer_35.0</th>\n",
       "      <th>manufacturer_36.0</th>\n",
       "      <th>manufacturer_42.0</th>\n",
       "      <th>manufacturer_43.0</th>\n",
       "      <th>...</th>\n",
       "      <th>curr_size_of_product_L    16 OZ</th>\n",
       "      <th>curr_size_of_product_L  7.75 OZ</th>\n",
       "      <th>curr_size_of_product_L 13.25 OZ</th>\n",
       "      <th>curr_size_of_product_LB</th>\n",
       "      <th>curr_size_of_product_N   12 OZ</th>\n",
       "      <th>curr_size_of_product_N   40 OZ</th>\n",
       "      <th>curr_size_of_product_PINT</th>\n",
       "      <th>curr_size_of_product_PK</th>\n",
       "      <th>curr_size_of_product_PT</th>\n",
       "      <th>curr_size_of_product_QT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         manufacturer_2.0  manufacturer_5.0  manufacturer_16.0  \\\n",
       "item_id                                                          \n",
       "117847                  0                 0                  0   \n",
       "818981                  0                 0                  0   \n",
       "\n",
       "         manufacturer_20.0  manufacturer_26.0  manufacturer_33.0  \\\n",
       "item_id                                                            \n",
       "117847                   0                  0                  0   \n",
       "818981                   0                  0                  0   \n",
       "\n",
       "         manufacturer_35.0  manufacturer_36.0  manufacturer_42.0  \\\n",
       "item_id                                                            \n",
       "117847                   0                  0                  0   \n",
       "818981                   0                  0                  0   \n",
       "\n",
       "         manufacturer_43.0  ...  curr_size_of_product_L    16 OZ  \\\n",
       "item_id                     ...                                    \n",
       "117847                   0  ...                                0   \n",
       "818981                   0  ...                                0   \n",
       "\n",
       "         curr_size_of_product_L  7.75 OZ  curr_size_of_product_L 13.25 OZ  \\\n",
       "item_id                                                                     \n",
       "117847                                 0                                0   \n",
       "818981                                 0                                0   \n",
       "\n",
       "         curr_size_of_product_LB  curr_size_of_product_N   12 OZ  \\\n",
       "item_id                                                            \n",
       "117847                         0                               0   \n",
       "818981                         0                               0   \n",
       "\n",
       "         curr_size_of_product_N   40 OZ  curr_size_of_product_PINT  \\\n",
       "item_id                                                              \n",
       "117847                                0                          0   \n",
       "818981                                0                          0   \n",
       "\n",
       "         curr_size_of_product_PK  curr_size_of_product_PT  \\\n",
       "item_id                                                     \n",
       "117847                         0                        0   \n",
       "818981                         0                        0   \n",
       "\n",
       "         curr_size_of_product_QT  \n",
       "item_id                           \n",
       "117847                         0  \n",
       "818981                         0  \n",
       "\n",
       "[2 rows x 2718 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_feat_lightfm.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LightFM(no_components=40,\n",
    "                loss='bpr',\n",
    "                # loss='warp',\n",
    "                learning_rate=0.01,\n",
    "                item_alpha=0.5,\n",
    "                user_alpha=0.5,\n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 941 ms, total: 1min 17s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1204c67c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=20,\n",
    "          num_threads=4,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_emb = model.get_user_representations(features=csr_matrix(user_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.830458,   0.      ,   0.      , ..., -15.662933,  -9.904337,\n",
       "         0.      ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_emb[0]  # biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.60977162e-06, -2.60512661e-06,  1.70567910e-06, ...,\n",
       "        -2.43383965e-05, -2.76305127e-06,  9.10889503e-06],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.91883628e-05,  1.45058129e-06, -2.02712181e-05, ...,\n",
       "         1.36510835e-05, -1.74547085e-06,  2.09315149e-05],\n",
       "       [ 9.85287261e-06,  2.04165517e-05, -4.74279987e-05, ...,\n",
       "        -2.74393878e-05,  1.01068317e-05,  8.09071753e-06],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_emb[1]  # embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_emb = model.get_item_representations(features=csr_matrix(item_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5001,), (5001, 40))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_emb[0].shape, item_emb[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21097319, 0.0024120605)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_precision = precision_at_k(model, sparse_user_item,\n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "test_precision = precision_at_k(model, test_sparse_user_item_matrix,\n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "train_precision, test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Params Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "?LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0\n",
      "user_alpha: 0\n",
      "learning_rate: 0.01\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0\n",
      "user_alpha: 0\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.1\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0\n",
      "learning_rate: 0.1\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.1\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0\n",
      "learning_rate: 0.1\n",
      "******Parameters failed:*****\n",
      "\\loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.01\n",
      "user_alpha: 0\n",
      "learning_rate: 0.05\n",
      "******Parameters failed:*****\n",
      "\\loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.01\n",
      "learning_rate: 0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         return self.fit_partial(\n\u001b[0m\u001b[1;32m    534\u001b[0m             \u001b[0minteractions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mfit_partial\u001b[0;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             self._run_epoch(\n\u001b[0m\u001b[1;32m    639\u001b[0m                 \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, item_features, user_features, interactions, sample_weight, num_threads, loss)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# Call the estimation routines.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             fit_warp(\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0mCSRMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0mCSRMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# no_components = [20, 30, 40, 50, 60]\n",
    "# item_alpha = [1e-2, 1e-1, 0]\n",
    "# user_alpha = [1e-2, 1e-1, 0]\n",
    "# learning_rate = [1e-2, 5e-2 , 1e-1]\n",
    "# loss = ['bpr', 'warp']\n",
    "#\n",
    "# result = pd.DataFrame(columns = ['no_components', 'item_alpha', 'user_alpha',\n",
    "#                                  'learning_rate', 'loss', 'train_precision@5', 'test_precision@5'])\n",
    "# i = 0\n",
    "# for l in loss:\n",
    "#     for c in no_components:\n",
    "#         for lr in learning_rate:\n",
    "#             for ia in item_alpha:\n",
    "#                 for ua in user_alpha:\n",
    "#                     try:\n",
    "#                         model = LightFM(no_components=c,\n",
    "#                                         loss=l,\n",
    "#                                         learning_rate=lr,\n",
    "#                                         item_alpha=ia,\n",
    "#                                         user_alpha=ua,\n",
    "#                                         random_state=42)\n",
    "#\n",
    "#                         model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "#                                   sample_weight=coo_matrix(user_item_matrix),\n",
    "#                                   user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "#                                   item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "#                                   epochs=15,\n",
    "#                                   num_threads=4,\n",
    "#                                   verbose=False)\n",
    "#\n",
    "#                         train_precision = precision_at_k(model, sparse_user_item,\n",
    "#                                                          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "#                                                          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "#                                                          k=5).mean()\n",
    "#\n",
    "#                         test_precision = precision_at_k(model, test_sparse_user_item_matrix,\n",
    "#                                                          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "#                                                          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "#                                                          k=5).mean()\n",
    "#\n",
    "#                         result.loc[i] = [c, ia, ua, lr, l, train_precision, test_precision]\n",
    "#\n",
    "#                         print(f\"{30*'-'}\\nloss: {l}\\nn_components: {c}\\nitem_alpha: {ia}\\nuser_alpha: {ua}\\nlearning_rate: {lr}\\ntrain precision@k: {train_precision:.4f}\\ntest precision@k: {test_precision:.4f}\")\n",
    "#\n",
    "#                     except ValueError:\n",
    "#                         result.loc[i] = [c, ia, ua, lr, l, np.nan, np.nan]\n",
    "#\n",
    "#                         print(f'******Parameters failed:*****\\n\\loss: {l}\\nn_components: {c}\\nitem_alpha: {ia}\\nuser_alpha: {ua}\\nlearning_rate: {lr}')\n",
    "#\n",
    "#                     i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_components</th>\n",
       "      <th>item_alpha</th>\n",
       "      <th>user_alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>train_precision@5</th>\n",
       "      <th>test_precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>0.419784</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>0.199760</td>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>0.347777</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>0.201362</td>\n",
       "      <td>0.002010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>0.438526</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>0.216099</td>\n",
       "      <td>0.001106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>0.276171</td>\n",
       "      <td>0.002513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>0.278574</td>\n",
       "      <td>0.003015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>0.061674</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>0.222587</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_components  item_alpha  user_alpha  learning_rate  loss  \\\n",
       "0              20        0.01        0.01           0.01   bpr   \n",
       "1              20        0.01        0.10           0.01   bpr   \n",
       "2              20        0.01        0.00           0.01   bpr   \n",
       "3              20        0.10        0.01           0.01   bpr   \n",
       "4              20        0.10        0.10           0.01   bpr   \n",
       "..            ...         ...         ...            ...   ...   \n",
       "265            60        0.10        0.10           0.10  warp   \n",
       "266            60        0.10        0.00           0.10  warp   \n",
       "267            60        0.00        0.01           0.10  warp   \n",
       "268            60        0.00        0.10           0.10  warp   \n",
       "269            60        0.00        0.00           0.10  warp   \n",
       "\n",
       "     train_precision@5  test_precision@5  \n",
       "0             0.419784          0.002613  \n",
       "1             0.199760          0.000603  \n",
       "2             0.347777          0.001910  \n",
       "3             0.201362          0.002010  \n",
       "4             0.438526          0.002814  \n",
       "..                 ...               ...  \n",
       "265           0.216099          0.001106  \n",
       "266           0.276171          0.002513  \n",
       "267           0.278574          0.003015  \n",
       "268           0.061674          0.002613  \n",
       "269           0.222587          0.002312  \n",
       "\n",
       "[270 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1398\n",
      "test precision@k: 0.0013\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1399\n",
      "test precision@k: 0.0012\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1427\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1613\n",
      "test precision@k: 0.0043\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2042\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2042\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1998\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2037\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2519\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2054\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2039\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2038\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2969\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2042\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2030\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2519\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2051\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2054\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2085\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1951\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.1953\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2084\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.1472\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1537\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2126\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2050\n",
      "test precision@k: 0.0155\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0039\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2104\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2050\n",
      "test precision@k: 0.0155\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2024\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2060\n",
      "test precision@k: 0.0038\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2059\n",
      "test precision@k: 0.0032\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0043\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0003\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2391\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2943\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2131\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2054\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1356\n",
      "test precision@k: 0.0014\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2141\n",
      "test precision@k: 0.0040\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2042\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0162\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2017\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2046\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2051\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2399\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2264\n",
      "test precision@k: 0.0189\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2050\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2082\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2113\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2082\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2024\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2082\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2086\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2098\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.0076\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2079\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2082\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2019\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2483\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2050\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.0062\n",
      "test precision@k: 0.0007\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0081\n",
      "test precision@k: 0.0013\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.0085\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2138\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2057\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1869\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2135\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2136\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2024\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2132\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2042\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2062\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.0133\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0161\n",
      "test precision@k: 0.0037\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.0082\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.0125\n",
      "test precision@k: 0.0014\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2017\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2887\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1407\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1418\n",
      "test precision@k: 0.0032\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1411\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2008\n",
      "test precision@k: 0.0056\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2010\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2035\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.0147\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2074\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1998\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2056\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2035\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2030\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2010\n",
      "test precision@k: 0.0058\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2084\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2010\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2012\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2066\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2054\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.1491\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1527\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1499\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2111\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2071\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2016\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.0036\n",
      "test precision@k: 0.0012\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2111\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2076\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2001\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2006\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0281\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0022\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1179\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.0993\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2107\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1918\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2131\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2115\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2229\n",
      "test precision@k: 0.0014\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2099\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2404\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2111\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2068\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2001\n",
      "test precision@k: 0.0144\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2396\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2040\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2082\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1638\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2057\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1604\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2097\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2111\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2118\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2111\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2020\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2041\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.0104\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0511\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.0067\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2191\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2137\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2137\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2116\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2078\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2120\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2004\n",
      "test precision@k: 0.0007\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epoch: 20\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epoch: 5\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0051\n",
      "test precision@k: 0.0007\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.0091\n",
      "test precision@k: 0.0021\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epoch: 20\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2874\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1374\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1414\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1435\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2011\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2076\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2034\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2107\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2014\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2005\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1997\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2018\n",
      "test precision@k: 0.0010\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.4385\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2399\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2026\n",
      "test precision@k: 0.0158\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2111\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2004\n",
      "test precision@k: 0.0013\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2081\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2016\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2082\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1990\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.1939\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2094\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1841\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.1554\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1551\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1511\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1549\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2098\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2045\n",
      "test precision@k: 0.0053\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2067\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2119\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2084\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2026\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2115\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2005\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0050\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2100\n",
      "test precision@k: 0.0014\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2028\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2097\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0022\n",
      "test precision@k: 0.0012\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2113\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2103\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2006\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0058\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2121\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2118\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0010\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.0068\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2304\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2028\n",
      "test precision@k: 0.0060\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2050\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1728\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2066\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2117\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1954\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1638\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2110\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2113\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2089\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2109\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2116\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.1882\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2105\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2075\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2076\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2056\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2060\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.0000\n",
      "test precision@k: 0.0000\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0090\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.0010\n",
      "test precision@k: 0.0004\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.0344\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2066\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2121\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2078\n",
      "test precision@k: 0.0021\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epoch: 20\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2120\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2109\n",
      "test precision@k: 0.0023\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epoch: 15\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epoch: 20\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.0627\n",
      "test precision@k: 0.0010\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0053\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2080\n",
      "test precision@k: 0.0025\n",
      "******Parameters failed:*****\n",
      "\\loss: bpr\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epoch: 20\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1540\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2785\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.0944\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1919\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1187\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1199\n",
      "test precision@k: 0.0009\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1226\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0982\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.0726\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2031\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1919\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0944\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0884\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1077\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1849\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1854\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2549\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2995\n",
      "test precision@k: 0.0009\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2085\n",
      "test precision@k: 0.0032\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1709\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2940\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.3809\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2445\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2161\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2762\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2928\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1644\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2914\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2942\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1000\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.3389\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2211\n",
      "test precision@k: 0.0137\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.3389\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2921\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2901\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2873\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.4178\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2545\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2545\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1132\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0779\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2157\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2405\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2131\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2243\n",
      "test precision@k: 0.0134\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2156\n",
      "test precision@k: 0.0130\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2138\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2161\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2244\n",
      "test precision@k: 0.0137\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2101\n",
      "test precision@k: 0.0037\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1230\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.1314\n",
      "test precision@k: 0.0013\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.0933\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2101\n",
      "test precision@k: 0.0046\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2227\n",
      "test precision@k: 0.0129\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2122\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2129\n",
      "test precision@k: 0.0039\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2187\n",
      "test precision@k: 0.0133\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2224\n",
      "test precision@k: 0.0133\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2116\n",
      "test precision@k: 0.0026\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2240\n",
      "test precision@k: 0.0135\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2205\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1681\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 20\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1339\n",
      "test precision@k: 0.0041\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2391\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1668\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.0513\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1252\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.0945\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.0756\n",
      "test precision@k: 0.0004\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2804\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1919\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2629\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1744\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1744\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1199\n",
      "test precision@k: 0.0009\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0944\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.1063\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1086\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.0900\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.0875\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2311\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2987\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2785\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2846\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2567\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.3047\n",
      "test precision@k: 0.0133\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2194\n",
      "test precision@k: 0.0139\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2244\n",
      "test precision@k: 0.0138\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2225\n",
      "test precision@k: 0.0127\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2145\n",
      "test precision@k: 0.0123\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2925\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2151\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.3938\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2942\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2194\n",
      "test precision@k: 0.0139\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2244\n",
      "test precision@k: 0.0138\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2545\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2187\n",
      "test precision@k: 0.0137\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2556\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2437\n",
      "test precision@k: 0.0007\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1981\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2332\n",
      "test precision@k: 0.0012\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2499\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2155\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.0807\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1157\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2339\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1733\n",
      "test precision@k: 0.0032\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1567\n",
      "test precision@k: 0.0103\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2109\n",
      "test precision@k: 0.0041\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2122\n",
      "test precision@k: 0.0037\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2129\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2073\n",
      "test precision@k: 0.0121\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2101\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2114\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2112\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2245\n",
      "test precision@k: 0.0138\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2837\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1600\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1638\n",
      "test precision@k: 0.0119\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2239\n",
      "test precision@k: 0.0125\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2220\n",
      "test precision@k: 0.0133\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2163\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2182\n",
      "test precision@k: 0.0131\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2123\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2236\n",
      "test precision@k: 0.0138\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2131\n",
      "test precision@k: 0.0022\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1506\n",
      "test precision@k: 0.0034\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0921\n",
      "test precision@k: 0.0012\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 40\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1564\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1573\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1689\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2618\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.2431\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1342\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.2785\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1035\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1482\n",
      "test precision@k: 0.0014\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.2391\n",
      "test precision@k: 0.0025\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1914\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 5\n",
      "train precision@k: 0.0919\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 10\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 15\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.01\n",
      "epochs: 20\n",
      "train precision@k: 0.1369\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.0771\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.1085\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.0886\n",
      "test precision@k: 0.0016\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.0897\n",
      "test precision@k: 0.0023\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2503\n",
      "test precision@k: 0.0018\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.3354\n",
      "test precision@k: 0.0014\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.0944\n",
      "test precision@k: 0.0005\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1000\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2551\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2155\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2161\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2134\n",
      "test precision@k: 0.0033\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1469\n",
      "test precision@k: 0.0011\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2843\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2862\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2147\n",
      "test precision@k: 0.0031\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.1577\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2916\n",
      "test precision@k: 0.0009\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.3708\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2940\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2941\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 5\n",
      "train precision@k: 0.2839\n",
      "test precision@k: 0.0008\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 10\n",
      "train precision@k: 0.2244\n",
      "test precision@k: 0.0138\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 15\n",
      "train precision@k: 0.2855\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.05\n",
      "epochs: 20\n",
      "train precision@k: 0.2163\n",
      "test precision@k: 0.0143\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2533\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1914\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2933\n",
      "test precision@k: 0.0028\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2561\n",
      "test precision@k: 0.0006\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1916\n",
      "test precision@k: 0.0024\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0893\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2573\n",
      "test precision@k: 0.0007\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2162\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1105\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.0814\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2040\n",
      "test precision@k: 0.0017\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.1\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1654\n",
      "test precision@k: 0.0114\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1799\n",
      "test precision@k: 0.0108\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1965\n",
      "test precision@k: 0.0119\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2105\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2247\n",
      "test precision@k: 0.0136\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2044\n",
      "test precision@k: 0.0114\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2091\n",
      "test precision@k: 0.0036\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2091\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2090\n",
      "test precision@k: 0.0030\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.3464\n",
      "test precision@k: 0.0035\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1043\n",
      "test precision@k: 0.0021\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2190\n",
      "test precision@k: 0.0138\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.5\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2785\n",
      "test precision@k: 0.0027\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.1923\n",
      "test precision@k: 0.0116\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2203\n",
      "test precision@k: 0.0117\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2202\n",
      "test precision@k: 0.0126\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.05\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.2022\n",
      "test precision@k: 0.0019\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2197\n",
      "test precision@k: 0.0114\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.2233\n",
      "test precision@k: 0.0119\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.2221\n",
      "test precision@k: 0.0133\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.1\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1999\n",
      "test precision@k: 0.0009\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 5\n",
      "train precision@k: 0.2084\n",
      "test precision@k: 0.0029\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 10\n",
      "train precision@k: 0.1314\n",
      "test precision@k: 0.0015\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 15\n",
      "train precision@k: 0.1475\n",
      "test precision@k: 0.0020\n",
      "------------------------------\n",
      "loss: warp\n",
      "n_components: 60\n",
      "item_alpha: 0.8\n",
      "user_alpha: 0.8\n",
      "learning_rate: 0.1\n",
      "epochs: 20\n",
      "train precision@k: 0.1903\n",
      "test precision@k: 0.0022\n",
      "CPU times: user 8h 37min 36s, sys: 1min 54s, total: 8h 39min 31s\n",
      "Wall time: 8h 43min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# так как на тесте результат не очень хороший, попробуем еще поменять параметр epochs в fit\n",
    "no_components = [20, 40, 60]\n",
    "item_alpha = [1e-1, 5e-1, 8e-1]\n",
    "user_alpha = [5e-2, 1e-1, 8e-1]\n",
    "learning_rate = [1e-2, 5e-2 , 1e-1]\n",
    "loss = ['bpr', 'warp']\n",
    "epochs = [5, 10, 15, 20]\n",
    "\n",
    "result = pd.DataFrame(columns = ['no_components', 'item_alpha', 'user_alpha',\n",
    "                                 'learning_rate', 'loss', 'epochs', 'train_precision@5', 'test_precision@5'])\n",
    "i = 0\n",
    "for l in loss:\n",
    "    for c in no_components:\n",
    "        for lr in learning_rate:\n",
    "            for ia in item_alpha:\n",
    "                for ua in user_alpha:\n",
    "                    model = LightFM(no_components=c,\n",
    "                                    loss=l,\n",
    "                                    learning_rate=lr,\n",
    "                                    item_alpha=ia,\n",
    "                                    user_alpha=ua,\n",
    "                                    random_state=42)\n",
    "                    for e in epochs:\n",
    "                        try:\n",
    "                            model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "                                      sample_weight=coo_matrix(user_item_matrix),\n",
    "                                      user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                      item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                      epochs=e,\n",
    "                                      num_threads=4,\n",
    "                                      verbose=False)\n",
    "\n",
    "                            train_precision = precision_at_k(model, sparse_user_item,\n",
    "                                                             user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                                             item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                                             k=5).mean()\n",
    "\n",
    "                            test_precision = precision_at_k(model, test_sparse_user_item_matrix,\n",
    "                                                            user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                                            item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                                            k=5).mean()\n",
    "\n",
    "                            result.loc[i] = [c, ia, ua, lr, l, e, train_precision, test_precision]\n",
    "\n",
    "                            print(f\"{30*'-'}\\nloss: {l}\\nn_components: {c}\\nitem_alpha: {ia}\\nuser_alpha: {ua}\\nlearning_rate: {lr}\\nepochs: {e}\\ntrain precision@k: {train_precision:.4f}\\ntest precision@k: {test_precision:.4f}\")\n",
    "\n",
    "                        except ValueError:\n",
    "                            result.loc[i] = [c, ia, ua, lr, l, e, np.nan, np.nan]\n",
    "\n",
    "                            print(f'******Parameters failed:*****\\n\\loss: {l}\\nn_components: {c}\\nitem_alpha: {ia}\\nuser_alpha: {ua}\\nlearning_rate: {lr}\\nepoch: {e}')\n",
    "\n",
    "                        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_components</th>\n",
       "      <th>item_alpha</th>\n",
       "      <th>user_alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_precision@5</th>\n",
       "      <th>test_precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>5</td>\n",
       "      <td>0.438526</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>10</td>\n",
       "      <td>0.438526</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>15</td>\n",
       "      <td>0.438526</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>20</td>\n",
       "      <td>0.438526</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>5</td>\n",
       "      <td>0.438526</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>20</td>\n",
       "      <td>0.199920</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>5</td>\n",
       "      <td>0.208410</td>\n",
       "      <td>0.002915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>10</td>\n",
       "      <td>0.131438</td>\n",
       "      <td>0.001508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>15</td>\n",
       "      <td>0.147537</td>\n",
       "      <td>0.002010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.10</td>\n",
       "      <td>warp</td>\n",
       "      <td>20</td>\n",
       "      <td>0.190308</td>\n",
       "      <td>0.002211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_components  item_alpha  user_alpha  learning_rate  loss epochs  \\\n",
       "0              20         0.1        0.05           0.01   bpr      5   \n",
       "1              20         0.1        0.05           0.01   bpr     10   \n",
       "2              20         0.1        0.05           0.01   bpr     15   \n",
       "3              20         0.1        0.05           0.01   bpr     20   \n",
       "4              20         0.1        0.10           0.01   bpr      5   \n",
       "..            ...         ...         ...            ...   ...    ...   \n",
       "643            60         0.8        0.10           0.10  warp     20   \n",
       "644            60         0.8        0.80           0.10  warp      5   \n",
       "645            60         0.8        0.80           0.10  warp     10   \n",
       "646            60         0.8        0.80           0.10  warp     15   \n",
       "647            60         0.8        0.80           0.10  warp     20   \n",
       "\n",
       "     train_precision@5  test_precision@5  \n",
       "0             0.438526          0.002814  \n",
       "1             0.438526          0.002814  \n",
       "2             0.438526          0.002814  \n",
       "3             0.438526          0.002814  \n",
       "4             0.438526          0.002814  \n",
       "..                 ...               ...  \n",
       "643           0.199920          0.000905  \n",
       "644           0.208410          0.002915  \n",
       "645           0.131438          0.001508  \n",
       "646           0.147537          0.002010  \n",
       "647           0.190308          0.002211  \n",
       "\n",
       "[648 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_components</th>\n",
       "      <th>item_alpha</th>\n",
       "      <th>user_alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_precision@5</th>\n",
       "      <th>test_precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>bpr</td>\n",
       "      <td>5</td>\n",
       "      <td>0.205046</td>\n",
       "      <td>0.015477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>bpr</td>\n",
       "      <td>5</td>\n",
       "      <td>0.205046</td>\n",
       "      <td>0.015477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.05</td>\n",
       "      <td>bpr</td>\n",
       "      <td>15</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.018894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>60</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bpr</td>\n",
       "      <td>10</td>\n",
       "      <td>0.202563</td>\n",
       "      <td>0.015779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_components  item_alpha  user_alpha  learning_rate loss epochs  \\\n",
       "48             20         0.5        0.05           0.05  bpr      5   \n",
       "52             20         0.5        0.10           0.05  bpr      5   \n",
       "70             20         0.8        0.80           0.05  bpr     15   \n",
       "245            60         0.8        0.10           0.01  bpr     10   \n",
       "\n",
       "     train_precision@5  test_precision@5  \n",
       "48            0.205046          0.015477  \n",
       "52            0.205046          0.015477  \n",
       "70            0.226432          0.018894  \n",
       "245           0.202563          0.015779  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result['test_precision@5'].values > 0.015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с параметрами, которые соответствуют лучшей метрике на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1204c62e0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=20,\n",
    "                loss='bpr',\n",
    "                learning_rate=0.05,\n",
    "                item_alpha=0.8,\n",
    "                user_alpha=0.8,\n",
    "                random_state=42)\n",
    "\n",
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15,\n",
    "          num_threads=4,\n",
    "          verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2084101, 0.0016080402)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_precision = precision_at_k(model, sparse_user_item,\n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "test_precision = precision_at_k(model, test_sparse_user_item_matrix,\n",
    "                                user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                k=5).mean()\n",
    "\n",
    "train_precision, test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
